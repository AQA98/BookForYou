{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "One of the biggest challenges when wanting to read books is finding the right book to read. That is why we made BookForYou. BookForYou is a recommender system that suggests books for the user based on their inputted preferences for author, title, and book category. It uses book reviews from Amazonâ€™s Book database to find the ideal book candidate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification of required data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used is [Amazon Book Reviews](https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews?select=books_data.csv).\n",
    "\n",
    "The dataset consists of two entities, one with book details and the second containing book reviews. Each entity has 10 features, for a combined dataset size of 3.04 GB. As shown below, one book can have many reviews, but a review can only belong to a single book. Books are identified by their titles. From the book details, the title, author, year and category will be used. From the reviews entity, the content of the reviews, book rating, and the helpfulness rating of a given review will be used.\n",
    "\n",
    "![Entities picture](images\\entities.png)\n",
    "\n",
    "For Book_details the following features will be used:\n",
    "For reviews the following features will be used:\n",
    "* Id (the id of the book)\n",
    "* title (Book Title)\n",
    "* user_id (Id of user who rate the book)\n",
    "* review/score (rating from 0 to 5 for the book)\n",
    "* review/summary (the summary of text review)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data PreProcessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following imports will be used for data preprocesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "# Spark imports\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc\n",
    "# Dask imports\n",
    "import dask.bag as db\n",
    "import dask.dataframe as df  # you can use Dask bags or dataframes\n",
    "from csv import reader\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviews\n",
    "Here we preprocess the reviews entity to the desired features mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------+------------+--------------------+\n",
      "|        Id|               Title|       User_id|review/score|      review/summary|\n",
      "+----------+--------------------+--------------+------------+--------------------+\n",
      "|1882931173|Its Only Art If I...| AVCGYZL8FQQTD|         4.0|Nice collection o...|\n",
      "|0826414346|Dr. Seuss: Americ...|A30TK6U7DNS82R|         5.0|   Really Enjoyed It|\n",
      "|0826414346|Dr. Seuss: Americ...|A3UH4UZ4RSVO82|         5.0|Essential for eve...|\n",
      "|0826414346|Dr. Seuss: Americ...|A2MVUWT453QH61|         4.0|Phlip Nel gives s...|\n",
      "|0826414346|Dr. Seuss: Americ...|A22X4XUPKF66MR|         4.0|Good academic ove...|\n",
      "|0826414346|Dr. Seuss: Americ...|A2F6NONFUDB6UK|         4.0|One of America's ...|\n",
      "|0826414346|Dr. Seuss: Americ...|A14OJS0VWMOSWO|         5.0|A memorably excel...|\n",
      "|0826414346|Dr. Seuss: Americ...|A2RSSXTDZDUSH4|         5.0|Academia At It's ...|\n",
      "|0826414346|Dr. Seuss: Americ...|A25MD5I2GUIW6W|         5.0|And to think that...|\n",
      "|0826414346|Dr. Seuss: Americ...|A3VA4XFS5WNJO3|         4.0|Fascinating accou...|\n",
      "|0829814000|Wonderful Worship...| AZ0IOBU20TBOP|         5.0|Outstanding Resou...|\n",
      "|0829814000|Wonderful Worship...|A373VVEU6Z9M0N|         5.0|Small Churches CA...|\n",
      "|0829814000|Wonderful Worship...| AGKGOH65VTRR4|         5.0|Not Just for Past...|\n",
      "|0829814000|Wonderful Worship...| A3OQWLU31BU1Y|         5.0|Small church past...|\n",
      "|0595344550|Whispers of the W...|A3Q12RK71N74LB|         1.0|            not good|\n",
      "|0595344550|Whispers of the W...|A1E9M6APK30ZAU|         4.0|  Here is my opinion|\n",
      "|0595344550|Whispers of the W...| AUR0VA5H0C66C|         1.0|        Buyer beware|\n",
      "|0595344550|Whispers of the W...|A1YLDZ3VHR6QPZ|         5.0| Fall on your knee's|\n",
      "|0595344550|Whispers of the W...| ACO23CG8K8T77|         5.0|      Bravo Veronica|\n",
      "|0595344550|Whispers of the W...|A1VK81CRRC7MLM|         5.0|           Wonderful|\n",
      "+----------+--------------------+--------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "2437387\n"
     ]
    }
   ],
   "source": [
    "spark  = init_spark()\n",
    "df = spark.read.csv(\"data\\\\preprocessed\\\\reviews.csv\", header=True)\n",
    "df = df.select(\"Id\", \"Title\", \"User_id\", \"review/score\", \"review/summary\")\n",
    "df = df.filter(df[\"Id\"] != '')\n",
    "df = df.filter(df[\"Title\"] != '')\n",
    "df = df.filter(df[\"User_id\"] != '')\n",
    "df = df.filter(df[\"review/score\"] != '')\n",
    "df = df.filter(df[\"review/summary\"] != '')\n",
    "df.show()\n",
    "print(df.count())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identification of required data\n",
    "In the `book_details.csv` file, we identify which data will be useful to our recommender system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#book_details = dd.read_csv('data/preprocessed/book_details.csv')\n",
    "book_ratings= dd.read_csv('data/preprocessed/reviews.csv', blocksize=1000)\n",
    "#book_details.head(10)\n",
    "book_ratings.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
