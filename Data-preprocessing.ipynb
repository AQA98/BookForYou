{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "One of the biggest challenges when wanting to read books is finding the right book to read. That is why we made BookForYou. BookForYou is a recommender system that suggests books for the user based on their inputted preferences for author, title, and book category. It uses book reviews from Amazonâ€™s Book database to find the ideal book candidate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification of required data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used is [Amazon Book Reviews](https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews?select=books_data.csv).\n",
    "\n",
    "The dataset consists of two entities, one with book details and the second containing book reviews. Each entity has 10 features, for a combined dataset size of 3.04 GB. As shown below, one book can have many reviews, but a review can only belong to a single book. Books are identified by their titles. From the book details, the title, author, year and category will be used. From the reviews entity, the content of the reviews, book rating, and the helpfulness rating of a given review will be used.\n",
    "\n",
    "![Entities picture](images\\entities.png)\n",
    "\n",
    "In the `book_details.csv` file, we will only keep some of the features. The following features will be removed\n",
    "-   image\n",
    "-   previewLink\n",
    "-   infoLink\n",
    "\n",
    "For null or empty values for the features being kept, we will\n",
    "-   Remove the entry if `title` is NULL\n",
    "-   Use the `reviews_text` feature if `description` is NULL\n",
    "-   Take the mean of other values in `publishedDate` if it is NULL\n",
    "    -   Only years will be kept"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data PreProcessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identification of required data\n",
    "In the `book_details.csv` file, we identify which data will be useful to our recommender system.\n",
    "For this entity, we will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# #book_details = dd.read_csv('data/preprocessed/book_details.csv')\n",
    "# book_ratings= dd.read_csv('data/preprocessed/reviews.csv', blocksize=1000)\n",
    "# #book_details.head(10)\n",
    "# book_ratings.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "# Spark imports\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc\n",
    "# Dask imports\n",
    "import dask.bag as db\n",
    "import dask.dataframe as details  # you can use Dask bags or dataframes\n",
    "from csv import reader\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark initialization\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|               Title|         description|             authors|           publisher|publishedDate|          categories|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|Its Only Art If I...|                null|    ['Julie Strain']|             Unknown|         1996|['Comics & Graphi...|\n",
      "|Dr. Seuss: Americ...|Philip Nel takes ...|      ['Philip Nel']|           A&C Black|   2005-01-01|['Biography & Aut...|\n",
      "|Wonderful Worship...|This resource inc...|    ['David R. Ray']|             Unknown|         2000|        ['Religion']|\n",
      "|Whispers of the W...|Julia Thomas find...| ['Veronica Haddon']|           iUniverse|      2005-02|         ['Fiction']|\n",
      "|Nation Dance: Rel...|                null|     ['Edward Long']|             Unknown|   2003-03-01|                null|\n",
      "|The Church of Chr...|In The Church of ...|['Everett Ferguson']|Wm. B. Eerdmans P...|         1996|        ['Religion']|\n",
      "|The Overbury affa...|                null|['Miriam Allen De...|             Unknown|         1960|                null|\n",
      "|A Walk in the Woo...|                null|    ['Lee Blessing']|             Unknown|         1988|                null|\n",
      "|Saint Hyacinth of...|The story for chi...|['Mary Fabyan Win...|     Tan Books & Pub|   2009-01-01|['Biography & Aut...|\n",
      "|Rising Sons and D...|Wardell recalls h...|  ['Steven Wardell']|  Plympton PressIntl|         1995|  ['Social Science']|\n",
      "|Muslim Women's Ch...|Counters the West...|['Camillia Fawzi ...|    Berg Pub Limited|   1994-02-17|        ['Religion']|\n",
      "|Dramatica for Scr...|Dramatica for Scr...|['Armando Salda A...|             Unknown|      2005-07|       ['Reference']|\n",
      "|Mensa Number Puzz...|Acclaimed teacher...|['Evelyn B. Chris...|            Sky Pony|   2018-11-06|['Juvenile Nonfic...|\n",
      "|Vector Quantizati...|Herb Caen a popul...|['Allen Gersho' '...|Springer Science ...|   2012-12-06|['Technology & En...|\n",
      "|A husband for Kutani|First published i...|      ['Frank Owen']|Pickle Partners P...|   2018-02-27|         ['History']|\n",
      "| Gold and greenstone|Sally did most th...|     ['Barry Crump']|             Unknown|         2009|['New Zealand fic...|\n",
      "|The Ultimate Guid...|This collection b...|    ['Fiona Cownie']|Bloomsbury Publis...|   2010-01-28|             ['Law']|\n",
      "|The Repeal of Ret...|At a time when Am...|['Rochelle Gurste...|       Hill and Wang|   2016-01-05|['Political Scien...|\n",
      "|Overcoming Hypert...|Like a time bomb ...|['Kenneth H. Coop...|              Bantam|   2012-02-01|['Health & Fitness']|\n",
      "|    Alaska Sourdough|Sourdough is a ma...|     ['Ruth Allman']|Alaska Northwest ...|         1976|         ['Cooking']|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# cols = [\"Title\", \"description\", \"authors\", \"publisher\", \"publishedDate\", \"categories\"]\n",
    "# df = pd.read_csv(\"data\\\\books_details.csv\", usecols = cols)\n",
    "\n",
    "# #df[[\"ratingsCount\"]]=df[[\"ratingsCount\"]].astype(str)\n",
    "\n",
    "# pandas_df = df.fillna(\"NULL VALUES\")\n",
    "# pandas_df[\"Title\"] = pandas_df[\"Title\"].astype(\"str\")\n",
    "# pandas_df[\"description\"] = pandas_df[\"description\"].astype(\"str\")\n",
    "# pandas_df[\"authors\"] = pandas_df[\"authors\"].astype(\"str\")\n",
    "# pandas_df[\"publisher\"] = pandas_df[\"publisher\"].astype(\"str\")\n",
    "# pandas_df[\"publishedDate\"] = pandas_df[\"publishedDate\"].astype(\"str\")\n",
    "# pandas_df[\"categories\"] = pandas_df[\"categories\"].astype(\"str\")\n",
    "\n",
    "\n",
    "# # pandas_df.head(40)\n",
    "# spark.conf.set(\"spark.sql.execution.arrow.enabled\",\"true\")\n",
    "\n",
    "# # Convert the Pandas DataFrame to a Spark DataFrame\n",
    "# sdf = spark.createDataFrame(pandas_df)\n",
    "\n",
    "# # Show the contents of the Spark DataFrame\n",
    "# sdf.show()\n",
    "\n",
    "\n",
    "spark  = init_spark()\n",
    "details = spark.read.csv(\"data\\\\output3.csv\", header=True)\n",
    "details = details.select(\"\"\"Title\"\"\", \"\"\"description\"\"\", \"\"\"authors\"\"\", \"\"\"publisher\"\"\", \"\"\"publishedDate\"\"\", \"\"\"categories\"\"\")\n",
    "#details = details.select( \"description\")\n",
    "\n",
    "#details=details.filter(details[\"description\"].contains(\",\"))\n",
    "\n",
    "details = details.filter(details[\"Title\"] != '')\n",
    "details = details.fillna({\"authors\":\"Unknown\"})\n",
    "details = details.fillna({\"publisher\":\"Unknown\"})\n",
    "details = details.fillna({\"publishedDate\":\"Unknown\"})\n",
    "\n",
    "details.dropna()\n",
    "details.show()\n",
    "\n",
    "\n",
    "# if description is null, use review text\n",
    "# i = 0\n",
    "# for row in details.collect():\n",
    "#   publish_date = row['publishedDate']\n",
    "#   i= i+1\n",
    "#   try:\n",
    "#     publish_date = datetime.strptime(publish_date, '%Y-%m-%d').date()\n",
    "\n",
    "#   except:\n",
    "#     print(f'row {row}')\n",
    "#     print(\"Bad dates:\", publish_date)\n",
    "\n",
    "#   if(i==7):\n",
    "#     break\n",
    "\n",
    "  # publish_date = datetime.strptime(publish_date, '%Y-%m-%d').date()\n",
    "  # publish_year = publish_date.year\n",
    "  # print(type(publish_date))\n",
    " \n",
    "    # print(details[row])\n",
    "    # break;\n",
    "# details = details.filter(details[\"User_id\"] != '')\n",
    "\n",
    "# details = details.filter(details[\"review/score\"] <= 5)\n",
    "# details = details.filter(details[\"review/score\"] >= 1)\n",
    "# no need to filter null values from review/summary\n",
    "# details.dropna()\n",
    "# details.show()\n",
    "# print(details.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def ignore_commas_and_quotes(input_file, output_file):\n",
    "    with open(input_file, 'r') as input_csv_file:\n",
    "        csv_reader = csv.reader(input_csv_file)\n",
    "        with open(output_file, 'w', newline='') as output_csv_file:\n",
    "            csv_writer = csv.writer(output_csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            for row in csv_reader:\n",
    "                new_row = []\n",
    "                for field in row:\n",
    "                    # Remove commas and double quotes from the field\n",
    "                    new_field = field.replace(',', '').replace('\"', '')\n",
    "                    new_field=new_field.strip()\n",
    "                    new_row.append(new_field)\n",
    "                csv_writer.writerow(new_row)\n",
    "\n",
    "\n",
    "ignore_commas_and_quotes(\"data\\\\books_details.csv\",\"data\\\\output.csv\")\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
