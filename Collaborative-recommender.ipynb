{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "One of the biggest challenges when wanting to read books is finding the right book to read. That is why we made BookForYou. BookForYou is a recommender system that suggests books for the user based on their inputted preferences for author, title, and book category. It uses book reviews from Amazonâ€™s Book database to find the ideal book candidate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification of required data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reviews the following features will be used:\n",
    "\n",
    "* Id (the id of the book)\n",
    "* title (Book Title)\n",
    "* user_id (Id of user who rate the book)\n",
    "* review/score (rating from 0 to 5 for the book)\n",
    "* review/summary (the summary of text review)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data PreProcessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following imports will be used for data preprocesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"BookForYou Recommender System\") \\\n",
    "        .config(\"spark.driver.memory\", \"8g\") \\\n",
    "        .config(\"spark.executor.memory\", \"8g\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark  = init_spark()\n",
    "df_ratings = spark.read.csv(\"data/preprocessed/reviews.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Data\n",
    "There may frequently be gaps in data sources, which leaves you with three main possibilities for completing the gaps\n",
    "\n",
    "1. Just keep the missing data points.\n",
    "2. Drop them missing data points (including the entire row)\n",
    "3. Fill them in with some other value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = df_ratings.select(\"Id\", \"Title\", \"User_id\", \"review/score\", \"review/summary\")\n",
    "df_ratings = df_ratings.na.drop(subset=[\"Id\",\"Title\",\"User_id\",\"review/score\",\"review/summary\"])\n",
    "df_ratings = df_ratings.withColumnRenamed(\"Id\", \"book_string\")\n",
    "df_ratings = df_ratings.withColumnRenamed(\"User_id\", \"User_string\")\n",
    "df_ratings = df_ratings.filter(df_ratings[\"review/score\"] <= 5)\n",
    "df_ratings = df_ratings.filter(df_ratings[\"review/score\"] >= 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering => based off ratings of other users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+------------+--------------------+\n",
      "|book_string|               Title|   User_string|review/score|      review/summary|\n",
      "+-----------+--------------------+--------------+------------+--------------------+\n",
      "| 1882931173|Its Only Art If I...| AVCGYZL8FQQTD|         4.0|Nice collection o...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A30TK6U7DNS82R|         5.0|   Really Enjoyed It|\n",
      "| 0826414346|Dr. Seuss: Americ...|A3UH4UZ4RSVO82|         5.0|Essential for eve...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A2MVUWT453QH61|         4.0|Phlip Nel gives s...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A22X4XUPKF66MR|         4.0|Good academic ove...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A2F6NONFUDB6UK|         4.0|One of America's ...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A14OJS0VWMOSWO|         5.0|A memorably excel...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A2RSSXTDZDUSH4|         5.0|Academia At It's ...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A25MD5I2GUIW6W|         5.0|And to think that...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A3VA4XFS5WNJO3|         4.0|Fascinating accou...|\n",
      "| 0829814000|Wonderful Worship...| AZ0IOBU20TBOP|         5.0|Outstanding Resou...|\n",
      "| 0829814000|Wonderful Worship...|A373VVEU6Z9M0N|         5.0|Small Churches CA...|\n",
      "| 0829814000|Wonderful Worship...| AGKGOH65VTRR4|         5.0|Not Just for Past...|\n",
      "| 0829814000|Wonderful Worship...| A3OQWLU31BU1Y|         5.0|Small church past...|\n",
      "| 0595344550|Whispers of the W...|A3Q12RK71N74LB|         1.0|            not good|\n",
      "| 0595344550|Whispers of the W...|A1E9M6APK30ZAU|         4.0|  Here is my opinion|\n",
      "| 0595344550|Whispers of the W...| AUR0VA5H0C66C|         1.0|        Buyer beware|\n",
      "| 0595344550|Whispers of the W...|A1YLDZ3VHR6QPZ|         5.0| Fall on your knee's|\n",
      "| 0595344550|Whispers of the W...| ACO23CG8K8T77|         5.0|      Bravo Veronica|\n",
      "| 0595344550|Whispers of the W...|A1VK81CRRC7MLM|         5.0|           Wonderful|\n",
      "+-----------+--------------------+--------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, book_string: string, Title: string, User_string: string, review/score: string, review/summary: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Create a StringIndexer for the \"User_id\" column\n",
    "indexer = StringIndexer(inputCols=[\"book_string\",\"User_string\",\"review/score\"], outputCols=[\"book_id\",\"User_id\",\"ratings\"])\n",
    "\n",
    "# Fit the StringIndexer to the DataFrame\n",
    "df_ratings = indexer.fit(df_ratings).transform(df_ratings).drop(\"book_string\",\"User_string\",\"review/score\")\n",
    "\n",
    "# Show the result\n",
    "#df_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+--------+-------+\n",
      "|               Title|      review/summary|book_id| User_id|ratings|\n",
      "+--------------------+--------------------+-------+--------+-------+\n",
      "|Dragons of the Dw...|Trying to fix a g...| 4434.0| 82277.0|    4.0|\n",
      "|Led Zeppelin: Daz...|   It all depends...|29089.0|777099.0|    4.0|\n",
      "|Dragons of the Dw...|Good Book! BAD E-...| 4434.0| 77266.0|    4.0|\n",
      "|Led Zeppelin: Daz...|Led Zeppelin Dese...|29089.0|  4796.0|    4.0|\n",
      "|Dragons of the Dw...|A disappointment;...| 4434.0| 89924.0|    4.0|\n",
      "|  Becoming Strangers|Do yourself a fav...|42794.0|578970.0|    4.0|\n",
      "|Dragons of the Dw...|I REALLY WANTED T...| 4434.0| 51150.0|    4.0|\n",
      "|  Becoming Strangers|This book is a wa...|42794.0|103704.0|    4.0|\n",
      "|The value of post...|             Alright|46176.0|291819.0|    4.0|\n",
      "|          RED LEAVES|Just OK-don't bot...| 7232.0|220507.0|    4.0|\n",
      "|Confessions of an...|It's not the Mess...|  162.0|  1199.0|    4.0|\n",
      "|Dragons of the Dw...|            terrible| 4434.0| 52812.0|    4.0|\n",
      "|Confessions of an...|A confession for ...|  162.0|626909.0|    4.0|\n",
      "|Dragons of the Dw...|Was the Editor on...| 4434.0| 80815.0|    4.0|\n",
      "|Confessions of an...|         UNsatsfying|  162.0|605865.0|    4.0|\n",
      "|Led Zeppelin: Daz...| Don't buy this book|29089.0|  7365.0|    4.0|\n",
      "|Confessions of an...|       Underwhelming|  162.0|333203.0|    4.0|\n",
      "|          RED LEAVES|   Depresssing Story| 7232.0|  8691.0|    4.0|\n",
      "|Confessions of an...|Self indulgent an...|  162.0|851735.0|    4.0|\n",
      "|Dragons of the Dw...|       Sloppy Effort| 4434.0|108680.0|    4.0|\n",
      "+--------------------+--------------------+-------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings.orderBy(desc(\"ratings\")).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_training_set, ratings_test_set = df_ratings.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS #alternating least squares algorithm\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "recommender = ALS(userCol=\"User_id\", itemCol=\"book_id\", ratingCol=\"ratings\", coldStartStrategy=\"drop\")\n",
    "recommender = recommender.fit(ratings_training_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322080"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = recommender.transform(ratings_test_set)\n",
    "#import pandas as pd\n",
    "predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-------+--------+-------+------------+\n",
      "|    Title|      review/summary|book_id| User_id|ratings|  prediction|\n",
      "+---------+--------------------+-------+--------+-------+------------+\n",
      "|The Giver|Nothing less than...|   26.0|   642.0|    0.0| -0.16424593|\n",
      "|The Giver|Just As Haunting ...|   26.0|  1025.0|    0.0| -0.13324575|\n",
      "|The Giver|Unabrid Audio 4 c...|   26.0|  1307.0|    0.0|  0.32836226|\n",
      "|The Giver|  Recovering Skeptic|   26.0|  1404.0|    0.0| 0.011291621|\n",
      "|The Giver|What a book!! Les...|   26.0|  1483.0|    0.0|-0.012859484|\n",
      "|The Giver| Inspirational Read!|   26.0|  1873.0|    0.0|   0.3416095|\n",
      "|The Giver|A Fable About The...|   26.0|  3691.0|    0.0|   0.9679783|\n",
      "|The Giver|  A Perfect Society?|   26.0|  5417.0|    0.0|  0.24573886|\n",
      "|The Giver|    Utopian distopia|   26.0| 12315.0|    1.0|   1.1893966|\n",
      "|The Giver|       Great Book!!!|   26.0| 26273.0|    0.0|  0.19406965|\n",
      "|The Giver|A life-changing book|   26.0| 29426.0|    0.0|         0.0|\n",
      "|The Giver|           The Giver|   26.0| 35021.0|    0.0|  0.61690533|\n",
      "|The Giver|Without sorrow......|   26.0| 79262.0|    1.0|         0.0|\n",
      "|The Giver|           The Giver|   26.0| 80522.0|    1.0|   0.7167869|\n",
      "|The Giver|   I Loved This Book|   26.0| 90524.0|    0.0|         0.0|\n",
      "|The Giver|Could have done m...|   26.0| 95809.0|    4.0|   0.8781464|\n",
      "|The Giver|Great book, bad e...|   26.0| 96954.0|    1.0|    0.913383|\n",
      "|The Giver|Ghastly! NOT for ...|   26.0|101659.0|    4.0|     3.40198|\n",
      "|The Giver|Twister for your ...|   26.0|109416.0|    0.0|         0.0|\n",
      "|The Giver|Great book, somew...|   26.0|115527.0|    0.0|         0.0|\n",
      "+---------+--------------------+-------+--------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutate the model\n",
    "\n",
    "Compute the Root-Mean Squared Error using LogisticRegression\n",
    "RMS = sqrt( sum(1,n) {pred - actual}^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.8822855895638484\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"ratings\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for threshold 3 or higher: 0.9681633878960805\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read the dataset into a pandas dataframe\n",
    "# Define a function to calculate precision\n",
    "def precision(data, threshold):\n",
    "    # Count the true positives and false positives\n",
    "    true_positives = data[(data[\"ratings\"] >= threshold) & (data[\"prediction\"] >= threshold)].count()\n",
    "    false_positives = data[(data[\"ratings\"] < threshold) & (data[\"prediction\"] >= threshold)].count()\n",
    "    # Calculate precision\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    return precision\n",
    "\n",
    "# Calculate precision for a rating threshold of 3 or higher\n",
    "p = precision(predictions, 3)\n",
    "print(\"Precision for threshold 3 or higher:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-eb3c95d1d479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Read the dataset into a pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Calculate recall for a rating threshold of 3 or higher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to calculate recall\n",
    "def recall(data, threshold):\n",
    "    # Count the true positives and false negatives\n",
    "    true_positives = data[(data[\"ratings\"] >= threshold) & (data[\"prediction\"] >= threshold)].count()\n",
    "    false_negatives = data[(data[\"ratings\"] >= threshold) & (data[\"prediction\"] < threshold)].count()\n",
    "    # Calculate recall\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    return recall\n",
    "\n",
    "# Calculate recall for a rating threshold of 3 or higher\n",
    "r = recall(predictions, 3)\n",
    "print(\"Recall for threshold 3 or higher:\", r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+-------+-------+\n",
      "|               Title|      review/summary| book_id|User_id|ratings|\n",
      "+--------------------+--------------------+--------+-------+-------+\n",
      "|Witness to Myself...|Terrific modern n...| 33535.0|  642.0|    0.0|\n",
      "|         Red Prophet|Slow going, but s...|  8659.0|  642.0|    2.0|\n",
      "|   Carry On, Jeeves!|Classic Wodehousi...|  7566.0|  642.0|    0.0|\n",
      "|     Nightmare House|A great audio of ...|  8136.0|  642.0|    0.0|\n",
      "|            Vendetta|Complex and inter...| 87914.0|  642.0|    0.0|\n",
      "|           The Giver|Nothing less than...|    26.0|  642.0|    0.0|\n",
      "|    A Stir of Echoes|One of his best; ...|  6264.0|  642.0|    0.0|\n",
      "|Donovan's Brain (...|      Landmark Novel|104538.0|  642.0|    1.0|\n",
      "| Beyond the Outposts|A great book in a...| 91328.0|  642.0|    0.0|\n",
      "|Claudius the god:...|The Sopranos of A...|  8208.0|  642.0|    0.0|\n",
      "|    Come Out Tonight|One of Laymon's best|213273.0|  642.0|    0.0|\n",
      "|Stranger in a Str...|Were my expectati...|   473.0|  642.0|    2.0|\n",
      "|The Big Rock Cand...|Terrific autobiog...| 10481.0|  642.0|    0.0|\n",
      "|Last Week's Apoca...|Solid debut colle...| 98585.0|  642.0|    1.0|\n",
      "|    Terrible Thrills|Great debut colle...|129622.0|  642.0|    1.0|\n",
      "|The Big Rock Cand...|Terrific autobiog...| 10579.0|  642.0|    0.0|\n",
      "|The New Shorter O...|Best dictionary f...|  5672.0|  642.0|    0.0|\n",
      "|  Tarzan of the Apes|&quot;A Ripping G...|  1803.0|  642.0|    0.0|\n",
      "|Donovan's Brain/H...|Great Introductio...|206031.0|  642.0|    1.0|\n",
      "|Stanger in a Stra...|Were my expectati...|   509.0|  642.0|    2.0|\n",
      "+--------------------+--------------------+--------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_test_set.filter(ratings_test_set[\"User_id\"] == 642.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = ratings_test_set.filter(ratings_test_set[\"User_id\"] == 642.0).select(\"book_id\",\"User_id\",\"Title\",\"review/summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------------------+--------------------+\n",
      "| book_id|User_id|               Title|      review/summary|\n",
      "+--------+-------+--------------------+--------------------+\n",
      "| 33535.0|  642.0|Witness to Myself...|Terrific modern n...|\n",
      "|  8659.0|  642.0|         Red Prophet|Slow going, but s...|\n",
      "|  7566.0|  642.0|   Carry On, Jeeves!|Classic Wodehousi...|\n",
      "|  8136.0|  642.0|     Nightmare House|A great audio of ...|\n",
      "| 87914.0|  642.0|            Vendetta|Complex and inter...|\n",
      "|    26.0|  642.0|           The Giver|Nothing less than...|\n",
      "|  6264.0|  642.0|    A Stir of Echoes|One of his best; ...|\n",
      "|104538.0|  642.0|Donovan's Brain (...|      Landmark Novel|\n",
      "| 91328.0|  642.0| Beyond the Outposts|A great book in a...|\n",
      "|  8208.0|  642.0|Claudius the god:...|The Sopranos of A...|\n",
      "|213273.0|  642.0|    Come Out Tonight|One of Laymon's best|\n",
      "|   473.0|  642.0|Stranger in a Str...|Were my expectati...|\n",
      "| 10481.0|  642.0|The Big Rock Cand...|Terrific autobiog...|\n",
      "| 98585.0|  642.0|Last Week's Apoca...|Solid debut colle...|\n",
      "|129622.0|  642.0|    Terrible Thrills|Great debut colle...|\n",
      "| 10579.0|  642.0|The Big Rock Cand...|Terrific autobiog...|\n",
      "|  5672.0|  642.0|The New Shorter O...|Best dictionary f...|\n",
      "|  1803.0|  642.0|  Tarzan of the Apes|&quot;A Ripping G...|\n",
      "|206031.0|  642.0|Donovan's Brain/H...|Great Introductio...|\n",
      "|   509.0|  642.0|Stanger in a Stra...|Were my expectati...|\n",
      "+--------+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = recommender.transform(test_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------------------+--------------------+-----------+\n",
      "| book_id|User_id|               Title|      review/summary| prediction|\n",
      "+--------+-------+--------------------+--------------------+-----------+\n",
      "|   473.0|  642.0|Stranger in a Str...|Were my expectati...|   1.593513|\n",
      "|   509.0|  642.0|Stanger in a Stra...|Were my expectati...|  1.5815586|\n",
      "|  8659.0|  642.0|         Red Prophet|Slow going, but s...|  1.3491691|\n",
      "|  8136.0|  642.0|     Nightmare House|A great audio of ...| 0.89534837|\n",
      "| 33535.0|  642.0|Witness to Myself...|Terrific modern n...|  0.8458453|\n",
      "|  6264.0|  642.0|    A Stir of Echoes|One of his best; ...|  0.8253751|\n",
      "|  5672.0|  642.0|The New Shorter O...|Best dictionary f...|  0.7862632|\n",
      "|104538.0|  642.0|Donovan's Brain (...|      Landmark Novel| 0.40847343|\n",
      "|  8208.0|  642.0|Claudius the god:...|The Sopranos of A...| 0.24503751|\n",
      "|  7566.0|  642.0|   Carry On, Jeeves!|Classic Wodehousi...| 0.22320217|\n",
      "|    26.0|  642.0|           The Giver|Nothing less than...| 0.18252607|\n",
      "| 10481.0|  642.0|The Big Rock Cand...|Terrific autobiog...| 0.15004706|\n",
      "| 10579.0|  642.0|The Big Rock Cand...|Terrific autobiog...| 0.12113099|\n",
      "| 98585.0|  642.0|Last Week's Apoca...|Solid debut colle...|        0.0|\n",
      "| 87914.0|  642.0|            Vendetta|Complex and inter...|        0.0|\n",
      "| 91328.0|  642.0| Beyond the Outposts|A great book in a...|        0.0|\n",
      "|129622.0|  642.0|    Terrible Thrills|Great debut colle...|        0.0|\n",
      "|  1803.0|  642.0|  Tarzan of the Apes|&quot;A Ripping G...|-0.01005419|\n",
      "+--------+-------+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations.orderBy(desc(\"prediction\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
