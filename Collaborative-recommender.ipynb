{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "One of the biggest challenges when wanting to read books is finding the right book to read. That is why we made BookForYou. BookForYou is a recommender system that suggests books for the user based on their inputted preferences for author, title, and book category. It uses book reviews from Amazonâ€™s Book database to find the ideal book candidate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification of required data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used is [Amazon Book Reviews](https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews?select=books_data.csv).\n",
    "\n",
    "The dataset consists of two entities, one with book details and the second containing book reviews. Each entity has 10 features, for a combined dataset size of 3.04 GB. As shown below, one book can have many reviews, but a review can only belong to a single book. Books are identified by their titles. From the book details, the title, author, year and category will be used. From the reviews entity, the content of the reviews, book rating, and the helpfulness rating of a given review will be used.\n",
    "\n",
    "![Entities picture](images\\entities.png)\n",
    "\n",
    "For Book_details the following features will be used:\n",
    "For reviews the following features will be used:\n",
    "\n",
    "# can check relevancy of features using correlation metrics (pearson similarity) of decision tree?\n",
    "* Id (the id of the book)\n",
    "* title (Book Title)\n",
    "* user_id (Id of user who rate the book)\n",
    "* review/score (rating from 0 to 5 for the book)\n",
    "* review/summary (the summary of text review)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data PreProcessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following imports will be used for data preprocesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"BookForYou Recommender System\") \\\n",
    "        .config(\"spark.driver.memory\", \"8g\") \\\n",
    "        .config(\"spark.executor.memory\", \"8g\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees for feature importance\n",
    "(USELESS CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # define the categorical features to one-hot encode\n",
    "# categorical_cols = ['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness', 'review/score', 'review/time', 'review/summary', 'review/text']\n",
    "\n",
    "\n",
    "# # create a list of string indexers for each categorical feature\n",
    "# indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\") for col in categorical_cols]\n",
    "\n",
    "# encoder = OneHotEncoder(inputCols=[indexer.getOutputCol() for indexer in indexers],\n",
    "#                                  outputCols=[col + \"_encoded\" for col in categorical_cols])\n",
    "\n",
    "# # fit the indexers and encoder to the data\n",
    "# indexers_models = [indexer.fit(df) for indexer in indexers]\n",
    "# encoded_df = encoder.fit(\n",
    "#     reduce(lambda data, model: model.transform(data), indexers_models, df)\n",
    "# ).transform(\n",
    "#     reduce(lambda data, model: model.transform(data), indexers_models, df)\n",
    "# )\n",
    "# print(encoded_df.columns)\n",
    "# dt = DecisionTreeClassifier(labelCol=\"review/score_index\", featuresCol='review/summary_encoded', maxDepth=2, maxBins=1000)\n",
    "# model = dt.fit(encoded_df)\n",
    "# print(model.featureImportances)\n",
    "# print(df.count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark  = init_spark()\n",
    "df_ratings = spark.read.csv(\"data\\\\preprocessed\\\\reviews.csv\", inferSchema=True, header=True)\n",
    "df_books = spark.read.csv(\"data\\\\preprocessed\\\\book_details.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Data\n",
    "There may frequently be gaps in data sources, which leaves you with three main possibilities for completing the gaps\n",
    "\n",
    "1. Just keep the missing data points.\n",
    "2. Drop them missing data points (including the entire row)\n",
    "3. Fill them in with some other value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = df_ratings.select(\"Id\", \"Title\", \"User_id\", \"review/score\", \"review/summary\")\n",
    "df_ratings = df_ratings.na.drop(subset=[\"Id\",\"Title\",\"User_id\",\"review/score\",\"review/summary\"])\n",
    "df_ratings = df_ratings.withColumnRenamed(\"Id\", \"book_string\")\n",
    "df_ratings = df_ratings.withColumnRenamed(\"User_id\", \"User_string\")\n",
    "df_ratings = df_ratings.filter(df_ratings[\"review/score\"] <= 5)\n",
    "df_ratings = df_ratings.filter(df_ratings[\"review/score\"] >= 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-based filtering => clustering issue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|               Title|         description|             authors|               image|         previewLink|           publisher|       publishedDate|            infoLink|          categories|        ratingsCount|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Its Only Art If I...|                null|    ['Julie Strain']|http://books.goog...|http://books.goog...|                null|                1996|http://books.goog...|['Comics & Graphi...|                null|\n",
      "|Dr. Seuss: Americ...|\"Philip Nel takes...| like that of Lew...| has changed lang...| giving us new wo...| inspiring artist...|      ['Philip Nel']|http://books.goog...|http://books.goog...|           A&C Black|\n",
      "|Wonderful Worship...|This resource inc...|    ['David R. Ray']|http://books.goog...|http://books.goog...|                null|                2000|http://books.goog...|        ['Religion']|                null|\n",
      "|Whispers of the W...|Julia Thomas find...| ['Veronica Haddon']|http://books.goog...|http://books.goog...|           iUniverse|             2005-02|http://books.goog...|         ['Fiction']|                null|\n",
      "|Nation Dance: Rel...|                null|     ['Edward Long']|                null|http://books.goog...|                null|          2003-03-01|http://books.goog...|                null|                null|\n",
      "|The Church of Chr...|In The Church of ...|['Everett Ferguson']|http://books.goog...|http://books.goog...|Wm. B. Eerdmans P...|                1996|http://books.goog...|        ['Religion']|                 5.0|\n",
      "|The Overbury affa...|                null|['Miriam Allen De...|                null|http://books.goog...|                null|                1960|http://books.goog...|                null|                null|\n",
      "|A Walk in the Woo...|                null|    ['Lee Blessing']|                null|http://books.goog...|                null|                1988|http://books.goog...|                null|                 3.0|\n",
      "|Saint Hyacinth of...|The story for chi...|['Mary Fabyan Win...|http://books.goog...|http://books.goog...|     Tan Books & Pub|          2009-01-01|http://books.goog...|['Biography & Aut...|                null|\n",
      "|Rising Sons and D...|Wardell recalls h...|  ['Steven Wardell']|                null|http://books.goog...|  Plympton PressIntl|                1995|http://books.goog...|  ['Social Science']|                null|\n",
      "|Muslim Women's Ch...|Counters the West...|['Camillia Fawzi ...|http://books.goog...|http://books.goog...|    Berg Pub Limited|          1994-02-17|http://books.goog...|        ['Religion']|                null|\n",
      "|Dramatica for Scr...|Dramatica for Scr...|['Armando Salda A...|http://books.goog...|http://books.goog...|                null|             2005-07|http://books.goog...|       ['Reference']|                null|\n",
      "|Mensa Number Puzz...|Acclaimed teacher...|['Evelyn B. Chris...|http://books.goog...|http://books.goog...|            Sky Pony|          2018-11-06|http://books.goog...|['Juvenile Nonfic...|                null|\n",
      "|Vector Quantizati...|\"Herb Caen, a pop...| but the statemen...|              i. e. | data compression...|               audio|              images| and video signal...|['Allen Gersho', ...|http://books.goog...|\n",
      "|A husband for Kutani|First published i...|      ['Frank Owen']|http://books.goog...|http://books.goog...|Pickle Partners P...|          2018-02-27|https://play.goog...|         ['History']|                null|\n",
      "| Gold and greenstone|Sally did most th...|     ['Barry Crump']|                null|http://books.goog...|                null|                2009|http://books.goog...|['New Zealand fic...|                null|\n",
      "|\"The Ultimate Gui...|This collection b...|    ['Fiona Cownie']|http://books.goog...|http://books.goog...|Bloomsbury Publis...|          2010-01-28|https://play.goog...|             ['Law']|                null|\n",
      "|The Repeal of Ret...|\"At a time when A...|       sex educators| and novelistsâ€”fr...| Gurstein offers ...|['Rochelle Gurste...|http://books.goog...|http://books.goog...|       Hill and Wang|          2016-01-05|\n",
      "|Overcoming Hypert...|Like a time bomb ...|['Kenneth H. Coop...|http://books.goog...|http://books.goog...|              Bantam|          2012-02-01|https://play.goog...|['Health & Fitness']|                null|\n",
      "|    Alaska Sourdough|\"\"\"Sourdough is a...| as author Ruth A...| this book includ...| three days to on...| there are more t...| loads of time-te...| and plenty of lo...| there are recipe...|     ['Ruth Allman']|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_books.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering => based off ratings of other users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2420208 ratings in the dataset\n",
      "+-----------+--------------------+--------------+------------+--------------------+\n",
      "|book_string|               Title|   User_string|review/score|      review/summary|\n",
      "+-----------+--------------------+--------------+------------+--------------------+\n",
      "| 1882931173|Its Only Art If I...| AVCGYZL8FQQTD|         4.0|Nice collection o...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A30TK6U7DNS82R|         5.0|   Really Enjoyed It|\n",
      "| 0826414346|Dr. Seuss: Americ...|A3UH4UZ4RSVO82|         5.0|Essential for eve...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A2MVUWT453QH61|         4.0|Phlip Nel gives s...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A22X4XUPKF66MR|         4.0|Good academic ove...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A2F6NONFUDB6UK|         4.0|One of America's ...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A14OJS0VWMOSWO|         5.0|A memorably excel...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A2RSSXTDZDUSH4|         5.0|Academia At It's ...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A25MD5I2GUIW6W|         5.0|And to think that...|\n",
      "| 0826414346|Dr. Seuss: Americ...|A3VA4XFS5WNJO3|         4.0|Fascinating accou...|\n",
      "| 0829814000|Wonderful Worship...| AZ0IOBU20TBOP|         5.0|Outstanding Resou...|\n",
      "| 0829814000|Wonderful Worship...|A373VVEU6Z9M0N|         5.0|Small Churches CA...|\n",
      "| 0829814000|Wonderful Worship...| AGKGOH65VTRR4|         5.0|Not Just for Past...|\n",
      "| 0829814000|Wonderful Worship...| A3OQWLU31BU1Y|         5.0|Small church past...|\n",
      "| 0595344550|Whispers of the W...|A3Q12RK71N74LB|         1.0|            not good|\n",
      "| 0595344550|Whispers of the W...|A1E9M6APK30ZAU|         4.0|  Here is my opinion|\n",
      "| 0595344550|Whispers of the W...| AUR0VA5H0C66C|         1.0|        Buyer beware|\n",
      "| 0595344550|Whispers of the W...|A1YLDZ3VHR6QPZ|         5.0| Fall on your knee's|\n",
      "| 0595344550|Whispers of the W...| ACO23CG8K8T77|         5.0|      Bravo Veronica|\n",
      "| 0595344550|Whispers of the W...|A1VK81CRRC7MLM|         5.0|           Wonderful|\n",
      "+-----------+--------------------+--------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('There are {} ratings in the dataset'.format(df_ratings.count()))\n",
    "df_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|summary|         book_string|               Title|         User_string|     review/score|      review/summary|\n",
      "+-------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|  count|             2420208|             2420208|             2420208|          2420208|             2420208|\n",
      "|   mean| 1.072548440143609E9|  2029.0781365666878|                null|4.227116429662244|            Infinity|\n",
      "| stddev|1.2973025907814867E9|  1738.2674242229316|                null|1.179690753614754|                 NaN|\n",
      "|    min|          0001047604|\"\"\" We'll Always ...|A00109803PZJ91RLT...|              1.0|                   !|\n",
      "|    max|          B0064P287I|xBase Programming...|       AZZZZW74AAX75|              5.0|~~~~~~~~~~~~~~~~~...|\n",
      "+-------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+--------+------+\n",
      "|               Title|      review/summary| book_id| User_id|rating|\n",
      "+--------------------+--------------------+--------+--------+------+\n",
      "|Its Only Art If I...|Nice collection o...|180201.0|167334.0|   1.0|\n",
      "|Dr. Seuss: Americ...|   Really Enjoyed It| 40116.0|    64.0|   0.0|\n",
      "|Dr. Seuss: Americ...|Essential for eve...| 40116.0|105599.0|   0.0|\n",
      "|Dr. Seuss: Americ...|Phlip Nel gives s...| 40116.0|  4472.0|   1.0|\n",
      "|Dr. Seuss: Americ...|Good academic ove...| 40116.0| 31627.0|   1.0|\n",
      "|Dr. Seuss: Americ...|One of America's ...| 40116.0|  3581.0|   1.0|\n",
      "|Dr. Seuss: Americ...|A memorably excel...| 40116.0|     0.0|   0.0|\n",
      "|Dr. Seuss: Americ...|Academia At It's ...| 40116.0|637113.0|   0.0|\n",
      "|Dr. Seuss: Americ...|And to think that...| 40116.0|130558.0|   0.0|\n",
      "|Dr. Seuss: Americ...|Fascinating accou...| 40116.0|837115.0|   1.0|\n",
      "|Wonderful Worship...|Outstanding Resou...| 76542.0|999164.0|   0.0|\n",
      "|Wonderful Worship...|Small Churches CA...| 76542.0|  6737.0|   0.0|\n",
      "|Wonderful Worship...|Not Just for Past...| 76542.0|905770.0|   0.0|\n",
      "|Wonderful Worship...|Small church past...| 76542.0|271312.0|   0.0|\n",
      "|Whispers of the W...|            not good| 11449.0|272659.0|   3.0|\n",
      "|Whispers of the W...|  Here is my opinion| 11449.0|385682.0|   1.0|\n",
      "|Whispers of the W...|        Buyer beware| 11449.0|307548.0|   3.0|\n",
      "|Whispers of the W...| Fall on your knee's| 11449.0| 38094.0|   0.0|\n",
      "|Whispers of the W...|      Bravo Veronica| 11449.0|885875.0|   0.0|\n",
      "|Whispers of the W...|           Wonderful| 11449.0|473482.0|   0.0|\n",
      "+--------------------+--------------------+--------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Create a StringIndexer for the \"User_id\" column\n",
    "indexer = StringIndexer(inputCols=[\"book_string\",\"User_string\",\"review/score\"], outputCols=[\"book_id\",\"User_id\",\"rating\"])\n",
    "\n",
    "# Fit the StringIndexer to the DataFrame\n",
    "df_ratings = indexer.fit(df_ratings).transform(df_ratings).drop(\"book_string\",\"User_string\",\"review/score\")\n",
    "\n",
    "# Show the result\n",
    "df_ratings.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_ratings\u001b[39m.\u001b[39mfilter(df_ratings[\u001b[39m\"\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m5.0\u001b[39m)\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_ratings' is not defined"
     ]
    }
   ],
   "source": [
    "df_ratings.filter(df_ratings[\"ratings\"] == 5.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_training_set, ratings_test_set = df_ratings.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS #alternating least squares algorithm\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "recommender = ALS(userCol=\"User_id\", itemCol=\"book_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "recommender = recommender.fit(ratings_training_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = recommender.transform(ratings_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-------+-------+------+------------+\n",
      "|    Title|      review/summary|book_id|User_id|rating|  prediction|\n",
      "+---------+--------------------+-------+-------+------+------------+\n",
      "|The Giver|Nothing less than...|   26.0|  642.0|   0.0|  0.19744895|\n",
      "|The Giver|Just As Haunting ...|   26.0| 1025.0|   0.0|   0.6680782|\n",
      "|The Giver|Unabrid Audio 4 c...|   26.0| 1307.0|   0.0|  0.45030588|\n",
      "|The Giver|  Recovering Skeptic|   26.0| 1404.0|   0.0|-0.057295006|\n",
      "|The Giver|What a book!! Les...|   26.0| 1483.0|   0.0|  0.12075398|\n",
      "|The Giver| Inspirational Read!|   26.0| 1873.0|   0.0|  0.43365362|\n",
      "|The Giver|A Fable About The...|   26.0| 3691.0|   0.0|  0.36760265|\n",
      "|The Giver|  A Perfect Society?|   26.0| 5417.0|   0.0|  0.19119999|\n",
      "|The Giver|    Utopian distopia|   26.0|12315.0|   1.0|   0.7907043|\n",
      "|The Giver|       Great Book!!!|   26.0|26273.0|   0.0|  0.28892416|\n",
      "+---------+--------------------+-------+-------+------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutate the model\n",
    "\n",
    "Compute the Root-Mean Squared Error using LogisticRegression\n",
    "RMS = sqrt( sum(1,n) {pred - actual}^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.8836118651317195\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+-------+------+\n",
      "|               Title|      review/summary| book_id|User_id|rating|\n",
      "+--------------------+--------------------+--------+-------+------+\n",
      "|Witness to Myself...|Terrific modern n...| 33535.0|  642.0|   0.0|\n",
      "|         Red Prophet|Slow going, but s...|  8659.0|  642.0|   2.0|\n",
      "|   Carry On, Jeeves!|Classic Wodehousi...|  7566.0|  642.0|   0.0|\n",
      "|     Nightmare House|A great audio of ...|  8136.0|  642.0|   0.0|\n",
      "|            Vendetta|Complex and inter...| 87914.0|  642.0|   0.0|\n",
      "|           The Giver|Nothing less than...|    26.0|  642.0|   0.0|\n",
      "|    A Stir of Echoes|One of his best; ...|  6264.0|  642.0|   0.0|\n",
      "|Donovan's Brain (...|      Landmark Novel|104538.0|  642.0|   1.0|\n",
      "| Beyond the Outposts|A great book in a...| 91328.0|  642.0|   0.0|\n",
      "|Claudius the god:...|The Sopranos of A...|  8208.0|  642.0|   0.0|\n",
      "|    Come Out Tonight|One of Laymon's best|213273.0|  642.0|   0.0|\n",
      "|Stranger in a Str...|Were my expectati...|   473.0|  642.0|   2.0|\n",
      "|The Big Rock Cand...|Terrific autobiog...| 10481.0|  642.0|   0.0|\n",
      "|Last Week's Apoca...|Solid debut colle...| 98585.0|  642.0|   1.0|\n",
      "|    Terrible Thrills|Great debut colle...|129622.0|  642.0|   1.0|\n",
      "|The Big Rock Cand...|Terrific autobiog...| 10579.0|  642.0|   0.0|\n",
      "|The New Shorter O...|Best dictionary f...|  5672.0|  642.0|   0.0|\n",
      "|  Tarzan of the Apes|&quot;A Ripping G...|  1803.0|  642.0|   0.0|\n",
      "|Donovan's Brain/H...|Great Introductio...|206031.0|  642.0|   1.0|\n",
      "|Stanger in a Stra...|Were my expectati...|   509.0|  642.0|   2.0|\n",
      "+--------------------+--------------------+--------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_test_set.filter(ratings_test_set[\"User_id\"] == 642.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = ratings_test_set.filter(ratings_test_set[\"User_id\"] == 642.0).select(\"book_id\",\"User_id\",\"Title\",\"review/summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------------------+--------------------+\n",
      "| book_id|User_id|               Title|      review/summary|\n",
      "+--------+-------+--------------------+--------------------+\n",
      "| 33535.0|  642.0|Witness to Myself...|Terrific modern n...|\n",
      "|  8659.0|  642.0|         Red Prophet|Slow going, but s...|\n",
      "|  7566.0|  642.0|   Carry On, Jeeves!|Classic Wodehousi...|\n",
      "|  8136.0|  642.0|     Nightmare House|A great audio of ...|\n",
      "| 87914.0|  642.0|            Vendetta|Complex and inter...|\n",
      "|    26.0|  642.0|           The Giver|Nothing less than...|\n",
      "|  6264.0|  642.0|    A Stir of Echoes|One of his best; ...|\n",
      "|104538.0|  642.0|Donovan's Brain (...|      Landmark Novel|\n",
      "| 91328.0|  642.0| Beyond the Outposts|A great book in a...|\n",
      "|  8208.0|  642.0|Claudius the god:...|The Sopranos of A...|\n",
      "|213273.0|  642.0|    Come Out Tonight|One of Laymon's best|\n",
      "|   473.0|  642.0|Stranger in a Str...|Were my expectati...|\n",
      "| 10481.0|  642.0|The Big Rock Cand...|Terrific autobiog...|\n",
      "| 98585.0|  642.0|Last Week's Apoca...|Solid debut colle...|\n",
      "|129622.0|  642.0|    Terrible Thrills|Great debut colle...|\n",
      "| 10579.0|  642.0|The Big Rock Cand...|Terrific autobiog...|\n",
      "|  5672.0|  642.0|The New Shorter O...|Best dictionary f...|\n",
      "|  1803.0|  642.0|  Tarzan of the Apes|&quot;A Ripping G...|\n",
      "|206031.0|  642.0|Donovan's Brain/H...|Great Introductio...|\n",
      "|   509.0|  642.0|Stanger in a Stra...|Were my expectati...|\n",
      "+--------+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = recommender.transform(test_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------------------+--------------------+------------+\n",
      "| book_id|User_id|               Title|      review/summary|  prediction|\n",
      "+--------+-------+--------------------+--------------------+------------+\n",
      "|   509.0|  642.0|Stanger in a Stra...|Were my expectati...|   1.5090193|\n",
      "|   473.0|  642.0|Stranger in a Str...|Were my expectati...|    1.481797|\n",
      "| 33535.0|  642.0|Witness to Myself...|Terrific modern n...|   1.2461519|\n",
      "|  8659.0|  642.0|         Red Prophet|Slow going, but s...|   0.9878093|\n",
      "|  7566.0|  642.0|   Carry On, Jeeves!|Classic Wodehousi...|  0.67062634|\n",
      "| 10481.0|  642.0|The Big Rock Cand...|Terrific autobiog...|   0.5467957|\n",
      "| 10579.0|  642.0|The Big Rock Cand...|Terrific autobiog...|  0.52053463|\n",
      "|  1803.0|  642.0|  Tarzan of the Apes|&quot;A Ripping G...|  0.35655648|\n",
      "|104538.0|  642.0|Donovan's Brain (...|      Landmark Novel|  0.35217682|\n",
      "|    26.0|  642.0|           The Giver|Nothing less than...|  0.19744895|\n",
      "|  5672.0|  642.0|The New Shorter O...|Best dictionary f...|  0.15244569|\n",
      "| 91328.0|  642.0| Beyond the Outposts|A great book in a...|         0.0|\n",
      "| 87914.0|  642.0|            Vendetta|Complex and inter...|         0.0|\n",
      "|129622.0|  642.0|    Terrible Thrills|Great debut colle...|         0.0|\n",
      "| 98585.0|  642.0|Last Week's Apoca...|Solid debut colle...|         0.0|\n",
      "|  8208.0|  642.0|Claudius the god:...|The Sopranos of A...|-0.012930636|\n",
      "|  8136.0|  642.0|     Nightmare House|A great audio of ...| -0.12379151|\n",
      "|  6264.0|  642.0|    A Stir of Echoes|One of his best; ...| -0.24333157|\n",
      "+--------+-------+--------------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations.orderBy(desc(\"prediction\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
